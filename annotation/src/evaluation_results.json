[
  {
    "model": "Gemma312B",
    "exact_match_accuracy": 0.9142390416553227,
    "Authority_precision": 0.0,
    "Authority_recall": 0.0,
    "Authority_f1": 0,
    "Authority_support": 15,
    "Consistency_precision": 0.06716417910447761,
    "Consistency_recall": 0.32142857142857145,
    "Consistency_f1": 0.1111111111111111,
    "Consistency_support": 28,
    "Friendship/Liking_precision": 0.021052631578947368,
    "Friendship/Liking_recall": 0.11764705882352941,
    "Friendship/Liking_f1": 0.035714285714285705,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.36363636363636365,
    "Reciprocation_recall": 0.17391304347826086,
    "Reciprocation_f1": 0.2352941176470588,
    "Reciprocation_support": 23,
    "Scarcity_precision": 0.05,
    "Scarcity_recall": 0.125,
    "Scarcity_f1": 0.07142857142857144,
    "Scarcity_support": 8,
    "Social Validation_precision": 0.02040816326530612,
    "Social Validation_recall": 0.038461538461538464,
    "Social Validation_f1": 0.026666666666666665,
    "Social Validation_support": 26,
    "macro_precision": 0.08704355626418246,
    "macro_recall": 0.12940836869865002,
    "macro_f1": 0.08003579209461562,
    "micro_precision": 0.05198776758409786,
    "micro_recall": 0.1452991452991453,
    "micro_f1": 0.07657657657657657,
    "hamming_loss": 0.018604229058898268,
    "Authority_gt_count": 15,
    "Authority_pred_count": 18,
    "Consistency_gt_count": 28,
    "Consistency_pred_count": 134,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 95,
    "Reciprocation_gt_count": 23,
    "Reciprocation_pred_count": 11,
    "Scarcity_gt_count": 8,
    "Scarcity_pred_count": 20,
    "Social Validation_gt_count": 26,
    "Social Validation_pred_count": 49
  },
  {
    "model": "Gemma31B",
    "exact_match_accuracy": 0.06859528780196839,
    "Authority_precision": 0.006772009029345372,
    "Authority_recall": 0.2727272727272727,
    "Authority_f1": 0.013215859030837005,
    "Authority_support": 11,
    "Consistency_precision": 0.005623242736644799,
    "Consistency_recall": 0.25,
    "Consistency_f1": 0.010999083409715858,
    "Consistency_support": 24,
    "Friendship/Liking_precision": 0.0075,
    "Friendship/Liking_recall": 0.17647058823529413,
    "Friendship/Liking_f1": 0.01438848920863309,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.0018832391713747645,
    "Reciprocation_recall": 0.047619047619047616,
    "Reciprocation_f1": 0.003623188405797101,
    "Reciprocation_support": 21,
    "Scarcity_precision": 0.0,
    "Scarcity_recall": 0.0,
    "Scarcity_f1": 0,
    "Scarcity_support": 7,
    "Social Validation_precision": 0.0064065230052417,
    "Social Validation_recall": 0.5,
    "Social Validation_f1": 0.012650948821161587,
    "Social Validation_support": 22,
    "macro_precision": 0.004697502323767773,
    "macro_recall": 0.20780281809693577,
    "macro_f1": 0.00914626147935744,
    "micro_precision": 0.0056510477984459614,
    "micro_recall": 0.23529411764705882,
    "micro_f1": 0.011037020004598757,
    "hamming_loss": 0.21378864698280148,
    "Authority_gt_count": 11,
    "Authority_pred_count": 443,
    "Consistency_gt_count": 24,
    "Consistency_pred_count": 1067,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 400,
    "Reciprocation_gt_count": 21,
    "Reciprocation_pred_count": 531,
    "Scarcity_gt_count": 7,
    "Scarcity_pred_count": 89,
    "Social Validation_gt_count": 22,
    "Social Validation_pred_count": 1717
  },
  {
    "model": "Gemma327B",
    "exact_match_accuracy": 0.8441872981700753,
    "Authority_precision": 0.0,
    "Authority_recall": 0.0,
    "Authority_f1": 0,
    "Authority_support": 17,
    "Consistency_precision": 0.03977272727272727,
    "Consistency_recall": 0.2413793103448276,
    "Consistency_f1": 0.06829268292682926,
    "Consistency_support": 29,
    "Friendship/Liking_precision": 0.03896103896103896,
    "Friendship/Liking_recall": 0.35294117647058826,
    "Friendship/Liking_f1": 0.07017543859649122,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.14705882352941177,
    "Reciprocation_recall": 0.21739130434782608,
    "Reciprocation_f1": 0.1754385964912281,
    "Reciprocation_support": 23,
    "Scarcity_precision": 0.07142857142857142,
    "Scarcity_recall": 0.375,
    "Scarcity_f1": 0.12,
    "Scarcity_support": 8,
    "Social Validation_precision": 0.049586776859504134,
    "Social Validation_recall": 0.2222222222222222,
    "Social Validation_f1": 0.08108108108108109,
    "Social Validation_support": 27,
    "macro_precision": 0.05780132300854226,
    "macro_recall": 0.23482233556424403,
    "macro_f1": 0.08583129984927161,
    "micro_precision": 0.046153846153846156,
    "micro_recall": 0.2231404958677686,
    "micro_f1": 0.07648725212464591,
    "hamming_loss": 0.02924291352709006,
    "Authority_gt_count": 17,
    "Authority_pred_count": 58,
    "Consistency_gt_count": 29,
    "Consistency_pred_count": 176,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 154,
    "Reciprocation_gt_count": 23,
    "Reciprocation_pred_count": 34,
    "Scarcity_gt_count": 8,
    "Scarcity_pred_count": 42,
    "Social Validation_gt_count": 27,
    "Social Validation_pred_count": 121
  },
  {
    "model": "Llama318B",
    "exact_match_accuracy": 0.49070331447049315,
    "Authority_precision": 0.014925373134328358,
    "Authority_recall": 0.17647058823529413,
    "Authority_f1": 0.02752293577981652,
    "Authority_support": 17,
    "Consistency_precision": 0.02843601895734597,
    "Consistency_recall": 0.41379310344827586,
    "Consistency_f1": 0.0532150776053215,
    "Consistency_support": 29,
    "Friendship/Liking_precision": 0.014492753623188406,
    "Friendship/Liking_recall": 0.23529411764705882,
    "Friendship/Liking_f1": 0.027303754266211604,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.016042780748663103,
    "Reciprocation_recall": 0.13043478260869565,
    "Reciprocation_f1": 0.028571428571428574,
    "Reciprocation_support": 23,
    "Scarcity_precision": 0.001034126163391934,
    "Scarcity_recall": 0.125,
    "Scarcity_f1": 0.0020512820512820513,
    "Scarcity_support": 8,
    "Social Validation_precision": 0.023076923076923078,
    "Social Validation_recall": 0.3333333333333333,
    "Social Validation_f1": 0.04316546762589929,
    "Social Validation_support": 27,
    "macro_precision": 0.016334662617306806,
    "macro_recall": 0.235720987545443,
    "macro_f1": 0.03030499098332659,
    "micro_precision": 0.013098649201801064,
    "micro_recall": 0.2644628099173554,
    "micro_f1": 0.0249609984399376,
    "hamming_loss": 0.11227881074283662,
    "Authority_gt_count": 17,
    "Authority_pred_count": 201,
    "Consistency_gt_count": 29,
    "Consistency_pred_count": 422,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 276,
    "Reciprocation_gt_count": 23,
    "Reciprocation_pred_count": 187,
    "Scarcity_gt_count": 8,
    "Scarcity_pred_count": 967,
    "Social Validation_gt_count": 27,
    "Social Validation_pred_count": 390
  },
  {
    "model": "Qwen2514B",
    "exact_match_accuracy": 0.8772165502418054,
    "Authority_precision": 0.02564102564102564,
    "Authority_recall": 0.125,
    "Authority_f1": 0.0425531914893617,
    "Authority_support": 16,
    "Consistency_precision": 0.05521472392638037,
    "Consistency_recall": 0.32142857142857145,
    "Consistency_f1": 0.09424083769633507,
    "Consistency_support": 28,
    "Friendship/Liking_precision": 0.1111111111111111,
    "Friendship/Liking_recall": 0.29411764705882354,
    "Friendship/Liking_f1": 0.16129032258064516,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.08,
    "Reciprocation_recall": 0.17391304347826086,
    "Reciprocation_f1": 0.1095890410958904,
    "Reciprocation_support": 23,
    "Scarcity_precision": 0.08,
    "Scarcity_recall": 0.25,
    "Scarcity_f1": 0.12121212121212122,
    "Scarcity_support": 8,
    "Social Validation_precision": 0.027777777777777776,
    "Social Validation_recall": 0.14814814814814814,
    "Social Validation_f1": 0.04678362573099414,
    "Social Validation_support": 27,
    "macro_precision": 0.06329077307604915,
    "macro_recall": 0.218767901685634,
    "macro_f1": 0.09594485663422463,
    "micro_precision": 0.05148514851485148,
    "micro_recall": 0.2184873949579832,
    "micro_f1": 0.08333333333333334,
    "hamming_loss": 0.025613469460863333,
    "Authority_gt_count": 16,
    "Authority_pred_count": 78,
    "Consistency_gt_count": 28,
    "Consistency_pred_count": 163,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 45,
    "Reciprocation_gt_count": 23,
    "Reciprocation_pred_count": 50,
    "Scarcity_gt_count": 8,
    "Scarcity_pred_count": 25,
    "Social Validation_gt_count": 27,
    "Social Validation_pred_count": 144
  },
  {
    "model": "Qwen2532B",
    "exact_match_accuracy": 0.8916599624564227,
    "Authority_precision": 0.0,
    "Authority_recall": 0.0,
    "Authority_f1": 0,
    "Authority_support": 17,
    "Consistency_precision": 0.05172413793103448,
    "Consistency_recall": 0.41379310344827586,
    "Consistency_f1": 0.09195402298850575,
    "Consistency_support": 29,
    "Friendship/Liking_precision": 0.1,
    "Friendship/Liking_recall": 0.23529411764705882,
    "Friendship/Liking_f1": 0.14035087719298245,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.13636363636363635,
    "Reciprocation_recall": 0.13043478260869565,
    "Reciprocation_f1": 0.1333333333333333,
    "Reciprocation_support": 23,
    "Scarcity_precision": 0.11764705882352941,
    "Scarcity_recall": 0.25,
    "Scarcity_f1": 0.15999999999999998,
    "Scarcity_support": 8,
    "Social Validation_precision": 0.04878048780487805,
    "Social Validation_recall": 0.14814814814814814,
    "Social Validation_f1": 0.07339449541284404,
    "Social Validation_support": 27,
    "macro_precision": 0.07575255348717971,
    "macro_recall": 0.19627835864202972,
    "macro_f1": 0.09983878815461093,
    "micro_precision": 0.06097560975609756,
    "micro_recall": 0.2066115702479339,
    "micro_f1": 0.09416195856873823,
    "hamming_loss": 0.02149816751586663,
    "Authority_gt_count": 17,
    "Authority_pred_count": 17,
    "Consistency_gt_count": 29,
    "Consistency_pred_count": 232,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 40,
    "Reciprocation_gt_count": 23,
    "Reciprocation_pred_count": 22,
    "Scarcity_gt_count": 8,
    "Scarcity_pred_count": 17,
    "Social Validation_gt_count": 27,
    "Social Validation_pred_count": 82
  },
  {
    "model": "Qwen2572B",
    "exact_match_accuracy": 0.8446471693050711,
    "Authority_precision": 0.047619047619047616,
    "Authority_recall": 0.29411764705882354,
    "Authority_f1": 0.0819672131147541,
    "Authority_support": 17,
    "Consistency_precision": 0.05232558139534884,
    "Consistency_recall": 0.6206896551724138,
    "Consistency_f1": 0.09651474530831099,
    "Consistency_support": 29,
    "Friendship/Liking_precision": 0.03305785123966942,
    "Friendship/Liking_recall": 0.23529411764705882,
    "Friendship/Liking_f1": 0.057971014492753624,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.2222222222222222,
    "Reciprocation_recall": 0.17391304347826086,
    "Reciprocation_f1": 0.1951219512195122,
    "Reciprocation_support": 23,
    "Scarcity_precision": 0.016216216216216217,
    "Scarcity_recall": 0.375,
    "Scarcity_f1": 0.031088082901554407,
    "Scarcity_support": 8,
    "Social Validation_precision": 0.030042918454935622,
    "Social Validation_recall": 0.25925925925925924,
    "Social Validation_f1": 0.05384615384615385,
    "Social Validation_support": 27,
    "macro_precision": 0.06691397285790665,
    "macro_recall": 0.3263789537693027,
    "macro_f1": 0.0860848601471732,
    "micro_precision": 0.040755467196819085,
    "micro_recall": 0.33884297520661155,
    "micro_f1": 0.07275953859804792,
    "hamming_loss": 0.04673106162239513,
    "Authority_gt_count": 17,
    "Authority_pred_count": 105,
    "Consistency_gt_count": 29,
    "Consistency_pred_count": 344,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 121,
    "Reciprocation_gt_count": 23,
    "Reciprocation_pred_count": 18,
    "Scarcity_gt_count": 8,
    "Scarcity_pred_count": 185,
    "Social Validation_gt_count": 27,
    "Social Validation_pred_count": 233
  },
  {
    "model": "Qwen257B",
    "exact_match_accuracy": 0.8805525460455038,
    "Authority_precision": 0.0,
    "Authority_recall": 0.0,
    "Authority_f1": 0,
    "Authority_support": 17,
    "Consistency_precision": 0.031007751937984496,
    "Consistency_recall": 0.13793103448275862,
    "Consistency_f1": 0.05063291139240506,
    "Consistency_support": 29,
    "Friendship/Liking_precision": 0.047619047619047616,
    "Friendship/Liking_recall": 0.11764705882352941,
    "Friendship/Liking_f1": 0.06779661016949151,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.0,
    "Reciprocation_recall": 0.0,
    "Reciprocation_f1": 0,
    "Reciprocation_support": 23,
    "Scarcity_precision": 0.041666666666666664,
    "Scarcity_recall": 0.25,
    "Scarcity_f1": 0.07142857142857142,
    "Scarcity_support": 8,
    "Social Validation_precision": 0.011428571428571429,
    "Social Validation_recall": 0.07407407407407407,
    "Social Validation_f1": 0.019801980198019802,
    "Social Validation_support": 27,
    "macro_precision": 0.021953672942045033,
    "macro_recall": 0.09660869456339367,
    "macro_f1": 0.034943345531414635,
    "micro_precision": 0.024271844660194174,
    "micro_recall": 0.08264462809917356,
    "micro_f1": 0.0375234521575985,
    "hamming_loss": 0.023158179848320692,
    "Authority_gt_count": 17,
    "Authority_pred_count": 8,
    "Consistency_gt_count": 29,
    "Consistency_pred_count": 129,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 42,
    "Reciprocation_gt_count": 23,
    "Reciprocation_pred_count": 10,
    "Scarcity_gt_count": 8,
    "Scarcity_pred_count": 48,
    "Social Validation_gt_count": 27,
    "Social Validation_pred_count": 175
  },
  {
    "model": "Qwen332B",
    "exact_match_accuracy": 0.8709417762275289,
    "Authority_precision": 0.09090909090909091,
    "Authority_recall": 0.29411764705882354,
    "Authority_f1": 0.1388888888888889,
    "Authority_support": 17,
    "Consistency_precision": 0.03571428571428571,
    "Consistency_recall": 0.13793103448275862,
    "Consistency_f1": 0.056737588652482275,
    "Consistency_support": 29,
    "Friendship/Liking_precision": 0.04395604395604396,
    "Friendship/Liking_recall": 0.23529411764705882,
    "Friendship/Liking_f1": 0.07407407407407408,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.4,
    "Reciprocation_recall": 0.17391304347826086,
    "Reciprocation_f1": 0.24242424242424243,
    "Reciprocation_support": 23,
    "Scarcity_precision": 0.0975609756097561,
    "Scarcity_recall": 0.5,
    "Scarcity_f1": 0.163265306122449,
    "Scarcity_support": 8,
    "Social Validation_precision": 0.03804347826086957,
    "Social Validation_recall": 0.25925925925925924,
    "Social Validation_f1": 0.06635071090047394,
    "Social Validation_support": 27,
    "macro_precision": 0.11769731240834104,
    "macro_recall": 0.2667525169876935,
    "macro_f1": 0.1236234685104351,
    "micro_precision": 0.056795131845841784,
    "micro_recall": 0.23140495867768596,
    "micro_f1": 0.09120521172638436,
    "hamming_loss": 0.024953045344781325,
    "Authority_gt_count": 17,
    "Authority_pred_count": 55,
    "Consistency_gt_count": 29,
    "Consistency_pred_count": 112,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 91,
    "Reciprocation_gt_count": 23,
    "Reciprocation_pred_count": 10,
    "Scarcity_gt_count": 8,
    "Scarcity_pred_count": 41,
    "Social Validation_gt_count": 27,
    "Social Validation_pred_count": 184
  },
  {
    "model": "llama3370B",
    "exact_match_accuracy": 0.8623557821303998,
    "Authority_precision": 0.02,
    "Authority_recall": 0.11764705882352941,
    "Authority_f1": 0.03418803418803419,
    "Authority_support": 17,
    "Consistency_precision": 0.06321839080459771,
    "Consistency_recall": 0.3793103448275862,
    "Consistency_f1": 0.10837438423645321,
    "Consistency_support": 29,
    "Friendship/Liking_precision": 0.043010752688172046,
    "Friendship/Liking_recall": 0.23529411764705882,
    "Friendship/Liking_f1": 0.07272727272727272,
    "Friendship/Liking_support": 17,
    "Reciprocation_precision": 0.3076923076923077,
    "Reciprocation_recall": 0.17391304347826086,
    "Reciprocation_f1": 0.2222222222222222,
    "Reciprocation_support": 23,
    "Scarcity_precision": 0.045454545454545456,
    "Scarcity_recall": 0.375,
    "Scarcity_f1": 0.08108108108108107,
    "Scarcity_support": 8,
    "Social Validation_precision": 0.028112449799196786,
    "Social Validation_recall": 0.25925925925925924,
    "Social Validation_f1": 0.05072463768115942,
    "Social Validation_support": 27,
    "macro_precision": 0.08458140773980329,
    "macro_recall": 0.2567373040059491,
    "macro_f1": 0.09488627202270379,
    "micro_precision": 0.04460431654676259,
    "micro_recall": 0.256198347107438,
    "micro_f1": 0.07598039215686274,
    "hamming_loss": 0.03371791431893391,
    "Authority_gt_count": 17,
    "Authority_pred_count": 100,
    "Consistency_gt_count": 29,
    "Consistency_pred_count": 174,
    "Friendship/Liking_gt_count": 17,
    "Friendship/Liking_pred_count": 93,
    "Reciprocation_gt_count": 23,
    "Reciprocation_pred_count": 13,
    "Scarcity_gt_count": 8,
    "Scarcity_pred_count": 66,
    "Social Validation_gt_count": 27,
    "Social Validation_pred_count": 249
  }
]